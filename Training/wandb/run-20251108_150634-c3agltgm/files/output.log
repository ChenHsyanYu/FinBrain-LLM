{'loss': 1.293, 'grad_norm': 0.111328125, 'learning_rate': 5.775231620503374e-05, 'epoch': 1.0}
{'eval_loss': 0.6084445118904114, 'eval_runtime': 150.5863, 'eval_samples_per_second': 9.795, 'eval_steps_per_second': 9.795, 'epoch': 1.0}
ğŸ“ˆ Step 52: eval_loss=0.6084 | ppl=1.84
{'loss': 0.5601, 'grad_norm': 0.10302734375, 'learning_rate': 4.5108696049072826e-05, 'epoch': 2.0}
{'eval_loss': 0.5677434206008911, 'eval_runtime': 150.7937, 'eval_samples_per_second': 9.782, 'eval_steps_per_second': 9.782, 'epoch': 2.0}
ğŸ“ˆ Step 104: eval_loss=0.5677 | ppl=1.76
{'loss': 0.5278, 'grad_norm': 0.10107421875, 'learning_rate': 2.624000299307087e-05, 'epoch': 3.0}
{'eval_loss': 0.5544045567512512, 'eval_runtime': 150.7805, 'eval_samples_per_second': 9.782, 'eval_steps_per_second': 9.782, 'epoch': 3.0}
ğŸ“ˆ Step 156: eval_loss=0.5544 | ppl=1.74
{'loss': 0.5144, 'grad_norm': 0.08349609375, 'learning_rate': 8.920500906034529e-06, 'epoch': 4.0}
{'eval_loss': 0.5510210990905762, 'eval_runtime': 151.0721, 'eval_samples_per_second': 9.764, 'eval_steps_per_second': 9.764, 'epoch': 4.0}
ğŸ“ˆ Step 208: eval_loss=0.5510 | ppl=1.74
{'loss': 0.5114, 'grad_norm': 0.08349609375, 'learning_rate': 2.861572291004644e-07, 'epoch': 5.0}
{'eval_loss': 0.5507773756980896, 'eval_runtime': 150.7424, 'eval_samples_per_second': 9.785, 'eval_steps_per_second': 9.785, 'epoch': 5.0}
ğŸ“ˆ Step 260: eval_loss=0.5508 | ppl=1.73
{'loss': 0.5113, 'grad_norm': 0.103515625, 'learning_rate': 5.6105512640085776e-05, 'epoch': 6.0}
{'eval_loss': 0.5408426523208618, 'eval_runtime': 150.7544, 'eval_samples_per_second': 9.784, 'eval_steps_per_second': 9.784, 'epoch': 6.0}
ğŸ“ˆ Step 312: eval_loss=0.5408 | ppl=1.72
{'loss': 0.4897, 'grad_norm': 0.09423828125, 'learning_rate': 4.1741210005116066e-05, 'epoch': 7.0}
{'eval_loss': 0.5308857560157776, 'eval_runtime': 150.7903, 'eval_samples_per_second': 9.782, 'eval_steps_per_second': 9.782, 'epoch': 7.0}
ğŸ“ˆ Step 364: eval_loss=0.5309 | ppl=1.70
{'loss': 0.4747, 'grad_norm': 0.10888671875, 'learning_rate': 2.2539303385054355e-05, 'epoch': 8.0}
{'eval_loss': 0.5265167951583862, 'eval_runtime': 150.8482, 'eval_samples_per_second': 9.778, 'eval_steps_per_second': 9.778, 'epoch': 8.0}
ğŸ“ˆ Step 416: eval_loss=0.5265 | ppl=1.69
{'loss': 0.4677, 'grad_norm': 0.0888671875, 'learning_rate': 6.411347035901432e-06, 'epoch': 9.0}
{'eval_loss': 0.5256072282791138, 'eval_runtime': 150.8683, 'eval_samples_per_second': 9.777, 'eval_steps_per_second': 9.777, 'epoch': 9.0}
ğŸ“ˆ Step 468: eval_loss=0.5256 | ppl=1.69
{'loss': 0.4662, 'grad_norm': 0.091796875, 'learning_rate': 2.368673885516648e-09, 'epoch': 10.0}
{'eval_loss': 0.5255569815635681, 'eval_runtime': 150.8424, 'eval_samples_per_second': 9.778, 'eval_steps_per_second': 9.778, 'epoch': 10.0}
ğŸ“ˆ Step 520: eval_loss=0.5256 | ppl=1.69
{'train_runtime': 15565.4606, 'train_samples_per_second': 8.524, 'train_steps_per_second': 0.033, 'train_loss': 0.5816448064950797, 'epoch': 10.0}
âœ… è¨“ç·´å®Œæˆ
   æœ€ä½³é©—è­‰ loss: 0.5256
ğŸ“ æ¨¡å‹å·²ä¿å­˜å®Œç•¢ã€‚
